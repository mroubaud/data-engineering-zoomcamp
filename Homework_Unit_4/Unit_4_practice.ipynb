{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a4296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-3.17.2-py2.py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-cloud-bigquery)\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-cloud-bigquery) (23.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (3.20.3)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.25.2)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery)\n",
      "  Downloading google_crc32c-1.5.0-cp311-cp311-macosx_10_9_universal2.whl (32 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.11.17)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/matiasroubaud/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.4.8)\n",
      "Downloading google_cloud_bigquery-3.17.2-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-crc32c, google-resumable-media, google-api-core, google-cloud-core, google-cloud-bigquery\n",
      "Successfully installed google-api-core-2.17.1 google-cloud-bigquery-3.17.2 google-cloud-core-2.4.1 google-crc32c-1.5.0 google-resumable-media-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac211f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dlt\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34118601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ee5fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23159064 entries, 0 to 23159063\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   dispatching_base_num    object        \n",
      " 1   pickup_datetime         datetime64[ns]\n",
      " 2   dropOff_datetime        datetime64[ns]\n",
      " 3   PUlocationID            float64       \n",
      " 4   DOlocationID            float64       \n",
      " 5   SR_Flag                 float64       \n",
      " 6   Affiliated_base_number  object        \n",
      "dtypes: datetime64[ns](2), float64(3), object(2)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed9d0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01 02:51:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>2019-01-01 00:54:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>2019-01-01 00:54:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:19:00</td>\n",
       "      <td>2019-01-01 00:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:27:00</td>\n",
       "      <td>2019-01-01 00:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00001 2019-01-01 00:30:00 2019-01-01 02:51:55           NaN   \n",
       "1               B00001 2019-01-01 00:45:00 2019-01-01 00:54:49           NaN   \n",
       "2               B00001 2019-01-01 00:15:00 2019-01-01 00:54:52           NaN   \n",
       "3               B00008 2019-01-01 00:19:00 2019-01-01 00:39:00           NaN   \n",
       "4               B00008 2019-01-01 00:27:00 2019-01-01 00:37:00           NaN   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           NaN      NaN                 B00001  \n",
       "1           NaN      NaN                 B00001  \n",
       "2           NaN      NaN                 B00001  \n",
       "3           NaN      NaN                 B00008  \n",
       "4           NaN      NaN                 B00008  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79debf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan, 140., 141., 237., 162., 145., 261.,  13., 249., 236., 171.,\n",
       "       252., 265., 229.,  16., 143., 142.,  88.,  87., 206., 221., 245.,\n",
       "       181., 257., 195., 138.,  25.,  89.,  70.,   7., 173.,  82.,  71.,\n",
       "       188.,  72., 129.,  56., 161.,  79., 234., 107., 137., 239., 130.,\n",
       "       189.,  32.,  81.,  51., 254., 264., 232.,  92.,  53., 192.,  15.,\n",
       "       132., 175., 121., 135., 156., 187.,  90.,  48., 112.,  18., 127.,\n",
       "       243., 144., 224., 263., 210., 147., 126., 168., 223.,  41., 119.,\n",
       "       205.,  38., 255.,  37.,  17., 163., 172., 251., 233., 260., 211.,\n",
       "        43., 102.,  36.,  76., 122., 159., 213., 226., 179., 167.,  69.,\n",
       "        47., 148.,  78., 235., 259., 231.,  68.,  61.,  49., 106.,  66.,\n",
       "       146., 174.,   3., 225.,  94., 191.,  35.,  29.,  97., 182., 170.,\n",
       "       247.,  33.,  65., 256., 176.,  50., 228.,  93.,  80.,  40., 164.,\n",
       "       113., 183., 134.,  95., 196.,  45., 244., 136., 198.,  62.,  52.,\n",
       "        85.,  14., 116., 131.,  22., 222., 185., 152.,  24., 158., 262.,\n",
       "       169., 212.,  98., 149.,  74., 220., 200., 178., 248.,  42., 177.,\n",
       "       160., 123.,  11., 203., 216.,  21., 108., 120., 166.,  26., 114.,\n",
       "        20., 151., 258.,  60., 241., 117.,   5.,  84., 109., 157., 242.,\n",
       "         4., 209., 197.,  75.,  39.,  86., 238., 227., 246., 125., 193.,\n",
       "        91., 133., 155., 165., 186., 100.,  44., 190., 215.,  83.,  55.,\n",
       "        67., 204., 150.,  54., 124.,  46.,  77., 230.,  64.,  63.,  58.,\n",
       "       115., 219., 201.,  28.,  73., 202., 250., 139., 180., 208.,  10.,\n",
       "       218., 217., 153.,  34.,  57., 118.,   9.,  23., 240.,  19., 214.,\n",
       "       101.,   6., 128.,  27.,  30.,  31.,   8., 111.,  12., 154.,  96.,\n",
       "       184., 110.,  99.,   1.,  59., 194., 253., 207.,   0.,   2., 199.,\n",
       "       105.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PUlocationID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a236430",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-02.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-03.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-04.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-05.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-06.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-07.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-08.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-09.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-10.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-11.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-12.parquet',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb0d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(year, service):\n",
    "    if service == 'fhv':\n",
    "        taxi_dtypes = {\n",
    "            'dispatching_base_num': str,\n",
    "            'PUlocationID': pd.Int64Dtype(),\n",
    "            'DOlocationID': pd.Int64Dtype(),\n",
    "            'SR_Flag': pd.Int64Dtype(),\n",
    "            'Affiliated_base_number': str,\n",
    "        }\n",
    "    else:\n",
    "        taxi_dtypes = {\n",
    "            'VendorID': pd.Int64Dtype(),\n",
    "            'passenger_count': pd.Int64Dtype(),\n",
    "            'trip_distance': float,\n",
    "            'RatecodeID': pd.Int64Dtype(),\n",
    "            'store_and_fwd_flag': str,\n",
    "            'PULocationID': pd.Int64Dtype(),\n",
    "            'DOLocationID': pd.Int64Dtype(),\n",
    "            'payment_type': pd.Int64Dtype(),\n",
    "            'fare_amount': float,\n",
    "            'extra': float,\n",
    "            'mta_tax': float,\n",
    "            'tip_amount': float,\n",
    "            'tolls_amount': float,\n",
    "            'improvement_surcharge': float,\n",
    "            'total_amount': float,\n",
    "            'congestion_surcharge': float ,\n",
    "            'trip_type': pd.Int64Dtype()\n",
    "        }\n",
    "\n",
    "    if service == 'green':\n",
    "        parse_dates = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']\n",
    "    elif service == 'yellow':\n",
    "        parse_dates = ['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    else:\n",
    "        parse_dates = ['pickup_datetime', 'dropOff_datetime']\n",
    "\n",
    "    for i in range(12):\n",
    "            \n",
    "        # sets the month part of the file_name string\n",
    "        month = '0'+str(i+1)\n",
    "        month = month[-2:]\n",
    "\n",
    "        # csv file_name\n",
    "        file_name = f\"{service}_tripdata_{year}-{month}.csv.gz\"\n",
    "\n",
    "        file_url = f\"{init_url}{service}/{file_name}\"\n",
    "\n",
    "        for row in pd.read_csv(file_url, sep=\",\", compression=\"gzip\", dtype=taxi_dtypes, parse_dates=parse_dates, iterator=True):\n",
    "            yield row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32df175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_to_gcs(year, service):\n",
    "    # define the connection to load to.\n",
    "    generators_pipeline = dlt.pipeline(destination='bigquery', dataset_name='trips_data_all')\n",
    "\n",
    "\n",
    "    # we can load any generator to a table at the pipeline destnation as follows:\n",
    "    info = generators_pipeline.run(load_csv(year, service),\n",
    "                                            table_name=f\"{service}_tripdata\",\n",
    "                                            write_disposition=\"append\")\n",
    "    \n",
    "    # the outcome metadata is returned by the load and we can inspect it by printing it.\n",
    "    print(info)\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    #client = bigquery.Client()\n",
    "\n",
    "    #query = \"\"\"\n",
    "        #SELECT *\n",
    "       # FROM f`ny_rides_all.{table_name}`\n",
    "    #\"\"\"\n",
    "\n",
    "    #client.query(query)  # Make an API request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d24367",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['project_id', 'private_key', 'client_email'] in configuration with spec GcpServiceAccountCredentials\n\tfor field \"project_id\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key CREDENTIALS__PROJECT_ID was not found.\n\tfor field \"private_key\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key CREDENTIALS__PRIVATE_KEY was not found.\n\tfor field \"client_email\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key CREDENTIALS__CLIENT_EMAIL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/matiasroubaud/Desktop/DE Zoomcamp/data-engineering-zoomcamp-main/04-analytics-engineering/Practice Code) is different from directory of your pipeline script (/Users/matiasroubaud/anaconda3/lib/python3.11/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:659\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    658\u001b[0m restored_schemas: Sequence[Schema] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m remote_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restore_state_from_destination()\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# if remote state is newer or same\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# print(f'REMOTE STATE: {(remote_state or {}).get(\"_state_version\")} >= {state[\"_state_version\"]}')\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# TODO: check if remote_state[\"_state_version\"] is not in 10 recent version. then we know remote is newer.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:1371\u001b[0m, in \u001b[0;36mPipeline._restore_state_from_destination\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(schema_name)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_destination_clients(schema)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m job_client:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job_client, WithStateSync):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:1122\u001b[0m, in \u001b[0;36mPipeline._get_destination_clients\u001b[0;34m(self, schema, initial_config, initial_staging_config)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# create instance with initial_config properly set\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdestination\u001b[38;5;241m.\u001b[39mclient(schema, initial_config)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client, staging_client\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/destination/reference.py:562\u001b[0m, in \u001b[0;36mDestination.client\u001b[0;34m(self, schema, initial_config)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a configured instance of the destination's job client\"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_class(schema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration(initial_config))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/destination/reference.py:475\u001b[0m, in \u001b[0;36mDestination.configuration\u001b[0;34m(self, initial_config)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a fully resolved destination config from the initial config\"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m config \u001b[38;5;241m=\u001b[39m resolve_configuration(\n\u001b[1;32m    476\u001b[0m     initial_config,\n\u001b[1;32m    477\u001b[0m     sections\u001b[38;5;241m=\u001b[39m(known_sections\u001b[38;5;241m.\u001b[39mDESTINATION, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdestination_name),\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# Already populated values will supersede resolved env config\u001b[39;00m\n\u001b[1;32m    479\u001b[0m     explicit_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_params,\n\u001b[1;32m    480\u001b[0m )\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:65\u001b[0m, in \u001b[0;36mresolve_configuration\u001b[0;34m(config, sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m     63\u001b[0m         log_traces(\u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m.\u001b[39m__section__, \u001b[38;5;28mtype\u001b[39m(config), explicit_value, \u001b[38;5;28;01mNone\u001b[39;00m, traces)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _resolve_configuration(config, sections, (), explicit_value, accept_partial)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:154\u001b[0m, in \u001b[0;36m_resolve_configuration\u001b[0;34m(config, explicit_sections, embedded_sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_resolved():\n\u001b[0;32m--> 154\u001b[0m     _resolve_config_fields(\n\u001b[1;32m    155\u001b[0m         config, explicit_value, explicit_sections, embedded_sections, accept_partial\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# full configuration was resolved\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:241\u001b[0m, in \u001b[0;36m_resolve_config_fields\u001b[0;34m(config, explicit_values, explicit_sections, embedded_sections, accept_partial)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m         current_value, traces \u001b[38;5;241m=\u001b[39m _resolve_config_field(\n\u001b[1;32m    242\u001b[0m             key,\n\u001b[1;32m    243\u001b[0m             hint,\n\u001b[1;32m    244\u001b[0m             default_value,\n\u001b[1;32m    245\u001b[0m             explicit_value,\n\u001b[1;32m    246\u001b[0m             config,\n\u001b[1;32m    247\u001b[0m             config\u001b[38;5;241m.\u001b[39m__section__,\n\u001b[1;32m    248\u001b[0m             explicit_sections,\n\u001b[1;32m    249\u001b[0m             embedded_sections,\n\u001b[1;32m    250\u001b[0m             accept_partial,\n\u001b[1;32m    251\u001b[0m         )\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# check if hint optional\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:357\u001b[0m, in \u001b[0;36m_resolve_config_field\u001b[0;34m(key, hint, default_value, explicit_value, config, config_sections, explicit_sections, embedded_sections, accept_partial)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# create new instance and pass value from the provider as initial, add key to sections\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m value \u001b[38;5;241m=\u001b[39m _resolve_configuration(\n\u001b[1;32m    358\u001b[0m     embedded_config,\n\u001b[1;32m    359\u001b[0m     explicit_sections,\n\u001b[1;32m    360\u001b[0m     embedded_sections \u001b[38;5;241m+\u001b[39m (key,),\n\u001b[1;32m    361\u001b[0m     default_value \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m value,\n\u001b[1;32m    362\u001b[0m     accept_partial,\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_partial() \u001b[38;5;129;01mand\u001b[39;00m is_optional:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# do not return partially resolved optional embeds\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:154\u001b[0m, in \u001b[0;36m_resolve_configuration\u001b[0;34m(config, explicit_sections, embedded_sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_resolved():\n\u001b[0;32m--> 154\u001b[0m     _resolve_config_fields(\n\u001b[1;32m    155\u001b[0m         config, explicit_value, explicit_sections, embedded_sections, accept_partial\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# full configuration was resolved\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/common/configuration/resolve.py:274\u001b[0m, in \u001b[0;36m_resolve_config_fields\u001b[0;34m(config, explicit_values, explicit_sections, embedded_sections, accept_partial)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unresolved_fields:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigFieldMissingException(\u001b[38;5;28mtype\u001b[39m(config)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, unresolved_fields)\n",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m: Following fields are missing: ['project_id', 'private_key', 'client_email'] in configuration with spec GcpServiceAccountCredentials\n\tfor field \"project_id\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key CREDENTIALS__PROJECT_ID was not found.\n\tfor field \"private_key\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key CREDENTIALS__PRIVATE_KEY was not found.\n\tfor field \"client_email\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key CREDENTIALS__CLIENT_EMAIL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/matiasroubaud/Desktop/DE Zoomcamp/data-engineering-zoomcamp-main/04-analytics-engineering/Practice Code) is different from directory of your pipeline script (/Users/matiasroubaud/anaconda3/lib/python3.11/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m init_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/DataTalksClub/nyc-tlc-data/releases/download/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#BUCKET = os.environ.get(\"GCP_GCS_BUCKET\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#web_to_gcs('2019', 'green')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#web_to_gcs('2020', 'yellow')\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m web_to_gcs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfhv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mweb_to_gcs\u001b[0;34m(year, service)\u001b[0m\n\u001b[1;32m      3\u001b[0m generators_pipeline \u001b[38;5;241m=\u001b[39m dlt\u001b[38;5;241m.\u001b[39mpipeline(destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbigquery\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrips_data_all\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# we can load any generator to a table at the pipeline destnation as follows:\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m info \u001b[38;5;241m=\u001b[39m generators_pipeline\u001b[38;5;241m.\u001b[39mrun(load_csv(year, service),\n\u001b[1;32m      8\u001b[0m                                         table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tripdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                         write_disposition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# the outcome metadata is returned by the load and we can inspect it by printing it.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(info)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:193\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    191\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:238\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    236\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    237\u001b[0m     ):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, schema_contract)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# sync state with destination\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrestore_from_destination\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_refresh\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdestination \u001b[38;5;129;01mor\u001b[39;00m destination)\n\u001b[1;32m    599\u001b[0m ):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_destination(destination, staging, dataset_name)\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# sync only once\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:164\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# refresh live schemas in storage or import schema path\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[0;32m--> 164\u001b[0m rv \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# save modified live schemas\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:730\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_state(state)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msync\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, ex, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['project_id', 'private_key', 'client_email'] in configuration with spec GcpServiceAccountCredentials\n\tfor field \"project_id\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PROJECT_ID was not found.\n\t\tIn Environment Variables key CREDENTIALS__PROJECT_ID was not found.\n\tfor field \"private_key\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__PRIVATE_KEY was not found.\n\t\tIn Environment Variables key CREDENTIALS__PRIVATE_KEY was not found.\n\tfor field \"client_email\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DLT_IPYKERNEL_LAUNCHER__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key DESTINATION__CREDENTIALS__CLIENT_EMAIL was not found.\n\t\tIn Environment Variables key CREDENTIALS__CLIENT_EMAIL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/matiasroubaud/Desktop/DE Zoomcamp/data-engineering-zoomcamp-main/04-analytics-engineering/Practice Code) is different from directory of your pipeline script (/Users/matiasroubaud/anaconda3/lib/python3.11/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials for more information\n"
     ]
    }
   ],
   "source": [
    "# services = ['fhv','green','yellow']\n",
    "init_url = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/'\n",
    "#BUCKET = os.environ.get(\"GCP_GCS_BUCKET\")\n",
    "\n",
    "#web_to_gcs('2019', 'green')\n",
    "\n",
    "#web_to_gcs('2020', 'green')\n",
    "\n",
    "#web_to_gcs('2019', 'yellow')\n",
    "\n",
    "#web_to_gcs('2020', 'yellow')\n",
    "\n",
    "web_to_gcs('2019', 'fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48468bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb92535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
